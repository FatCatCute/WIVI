import json
import os

file_path = r"C:\Users\admin\Documents\Counting Activity for CV-CSI\wivi_project\src\multimodal_activity_recognition.ipynb"

# 1. New Dataset Class Code (Reads from CSV)
dataset_code = [
    "# Custom Dataset Class for Activity Recognition (CSV Based)\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, dataset_path, split='train', transform=None, task='classification', verbose=True):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.transform = transform\n",
    "        self.task = task\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # 1. Discover Classes\n",
    "        self.classes = sorted([d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))])\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        if self.verbose and split == 'train':\n",
    "            print(f\"Found {len(self.classes)} classes: {self.classes}\")\n",
    "        \n",
    "        # 2. Collect All Samples from CSVs\n",
    "        self.samples = []\n",
    "        for cls_name in self.classes:\n",
    "            cls_dir = os.path.join(dataset_path, cls_name)\n",
    "            csi_dir = os.path.join(cls_dir, 'csi')\n",
    "            img_dir = os.path.join(cls_dir, 'images')\n",
    "            \n",
    "            # Find the CSV file in csi folder\n",
    "            if not os.path.exists(csi_dir):\n",
    "                continue\n",
    "            \n",
    "            csv_files = [f for f in os.listdir(csi_dir) if f.endswith('.csv')]\n",
    "            if not csv_files:\n",
    "                if self.verbose: print(f\"No CSV found in {csi_dir}\")\n",
    "                continue\n",
    "                \n",
    "            # Assuming one main CSV per class or read all\n",
    "            for csv_file in csv_files:\n",
    "                csv_path = os.path.join(csi_dir, csv_file)\n",
    "                try:\n",
    "                    df = pd.read_csv(csv_path)\n",
    "                    # Expected columns: image_filename, normalized_csi_data, ...\n",
    "                    if 'image_filename' not in df.columns or 'normalized_csi_data' not in df.columns:\n",
    "                        if self.verbose: print(f\"Skipping {csv_file}: missing columns\")\n",
    "                        continue\n",
    "                    \n",
    "                    for _, row in df.iterrows():\n",
    "                        img_name = row['image_filename']\n",
    "                        csi_str = row['normalized_csi_data']\n",
    "                        \n",
    "                        img_full_path = os.path.join(img_dir, img_name)\n",
    "                        if os.path.exists(img_full_path):\n",
    "                            self.samples.append({\n",
    "                                'img_path': img_full_path,\n",
    "                                'csi_data': csi_str,\n",
    "                                'label': self.class_to_idx[cls_name],\n",
    "                                'class_name': cls_name\n",
    "                            })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {csv_path}: {e}\")\n",
    "\n",
    "        # 3. Split Data (80-10-10)\n",
    "        np.random.seed(42)\n",
    "        indices = np.random.permutation(len(self.samples))\n",
    "        n_total = len(indices)\n",
    "        train_end = int(n_total * 0.8)\n",
    "        val_end = int(n_total * 0.9)\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.indices = indices[:train_end]\n",
    "        elif split == 'val':\n",
    "            self.indices = indices[train_end:val_end]\n",
    "        else: # test\n",
    "            self.indices = indices[val_end:]\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(f\"[{split.upper()}] Loaded {len(self.indices)} samples out of {len(self.samples)} total.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        sample_info = self.samples[real_idx]\n",
    "        \n",
    "        # Load CSI\n",
    "        try:\n",
    "            # Parse string representation of list\n",
    "            csi_raw = ast.literal_eval(sample_info['csi_data'])\n",
    "            csi_data = np.array(csi_raw, dtype=np.float32)\n",
    "            \n",
    "            # Pad or truncate\n",
    "            if len(csi_data) > CSI_LENGTH:\n",
    "                csi_data = csi_data[:CSI_LENGTH]\n",
    "            else:\n",
    "                pad_width = CSI_LENGTH - len(csi_data)\n",
    "                csi_data = np.pad(csi_data, (0, pad_width), 'constant')\n",
    "                \n",
    "            csi_tensor = torch.tensor(csi_data, dtype=torch.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # print(f\"Error parsing CSI: {e}\")\n",
    "            csi_tensor = torch.zeros(CSI_LENGTH, dtype=torch.float32)\n",
    "\n",
    "        # Load Image\n",
    "        try:\n",
    "            image = Image.open(sample_info['img_path']).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Image {sample_info['img_path']}: {e}\")\n",
    "            image = torch.zeros((3, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        # Label\n",
    "        label = torch.tensor(sample_info['label'], dtype=torch.long)\n",
    "        \n",
    "        return csi_tensor, image, label\n"
]

# 2. New Model Architecture Code
model_code = [
    "# Model Architecture\n",
    "\n",
    "class CSIEncoder(nn.Module):\n",
    "    def __init__(self, input_len=100, embed_dim=128):\n",
    "        super(CSIEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Calculate output size after 3 pools\n",
    "        # 100 -> 50 -> 25 -> 12\n",
    "        self.fc = nn.Linear(128 * 12, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, length] -> [batch, 1, length]\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=128):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        # Use ResNet18 but remove last fc\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(512, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, num_classes=8, mode='fusion'):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.csi_encoder = CSIEncoder(input_len=CSI_LENGTH, embed_dim=128)\n",
    "        self.img_encoder = ImageEncoder(embed_dim=128)\n",
    "        \n",
    "        if mode == 'fusion':\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(128, num_classes)\n",
    "            )\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(64, num_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, csi, img):\n",
    "        if self.mode == 'csi_only':\n",
    "            feat = self.csi_encoder(csi)\n",
    "        elif self.mode == 'img_only':\n",
    "            feat = self.img_encoder(img)\n",
    "        else: # fusion\n",
    "            csi_feat = self.csi_encoder(csi)\n",
    "            img_feat = self.img_encoder(img)\n",
    "            feat = torch.cat((csi_feat, img_feat), dim=1)\n",
    "            \n",
    "        out = self.classifier(feat)\n",
    "        return out\n"
]

# 3. Training Loop Update (To run 3 experiments)
training_code = [
    "# Main Training Execution\n",
    "\n",
    "modes = ['img_only', 'csi_only', 'fusion']\n",
    "results = {}\n",
    "\n",
    "for mode in modes:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"STARTING TRAINING MODE: {mode.upper()}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Initialize Model\n",
    "    model = FusionModel(num_classes=len(train_dataset.classes), mode=mode).to(device)\n",
    "    \n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training Loop\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for csi, img, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            csi, img, labels = csi.to(device), img.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(csi, img)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        train_acc = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for csi, img, labels in val_loader:\n",
    "                csi, img, labels = csi.to(device), img.to(device), labels.to(device)\n",
    "                outputs = model(csi, img)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct / total\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, f'best_model_{mode}.pth'))\n",
    "    \n",
    "    results[mode] = best_val_acc\n",
    "    print(f\"Best Val Acc for {mode}: {best_val_acc:.2f}%\")\n",
    "\n",
    "print(\"\\nFinal Results Summary:\")\n",
    "for mode, acc in results.items():\n",
    "    print(f\"{mode}: {acc:.2f}%\")\n"
]

with open(file_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# Update Dataset Cell (Assuming index 6 from previous check)
nb['cells'][6]['source'] = dataset_code

# Update Model Cell (Need to find where model was defined, usually after dataset)
# Let's append a new cell for Model if we can't find it easily, or replace the old model cell.
# I'll search for "class MultiTaskModel" or similar to replace.
model_cell_idx = -1
for i, cell in enumerate(nb['cells']):
    if cell['cell_type'] == 'code' and "class" in "".join(cell['source']) and "nn.Module" in "".join(cell['source']):
        model_cell_idx = i
        break

if model_cell_idx != -1:
    nb['cells'][model_cell_idx]['source'] = model_code
else:
    # Insert after dataset
    nb['cells'].insert(7, {'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': model_code})

# Update Training Loop Cell
# Search for "TRAINING MULTIPLE TASKS" or similar
train_cell_idx = -1
for i, cell in enumerate(nb['cells']):
    if cell['cell_type'] == 'code' and "TRAINING MULTIPLE TASKS" in "".join(cell['source']):
        train_cell_idx = i
        break

if train_cell_idx != -1:
    nb['cells'][train_cell_idx]['source'] = training_code
else:
    # Append to end
    nb['cells'].append({'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': training_code})

with open(file_path, 'w', encoding='utf-8') as f:
    json.dump(nb, f, indent=1)

print("Notebook updated with V2 changes!")
